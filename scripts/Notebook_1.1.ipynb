{"cells":[{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# %pip install tensorflow==2.6.2"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2.6.2\n"]}],"source":["# Importing libraries\n","\n","import tensorflow as tf\n","import tensorflow.keras as tfk\n","import tensorflow.keras.layers as tfkl\n","import numpy as np\n","import scipy.io\n","import os\n","import random\n","import pandas as pd\n","import seaborn as sns\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","import keras.backend as K\n","import numpy as np\n","import os\n","import random\n","import seaborn as sns\n","from datetime import datetime\n","from random import randrange\n","import matplotlib.pyplot as plt\n","import math\n","plt.rc('font', size=16)\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.layers import Lambda\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense, Bidirectional, Concatenate\n","from tensorflow.keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Input, BatchNormalization, \\\n","    multiply, concatenate, Flatten, Activation, dot\n","from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import Sequence\n","from tensorflow.keras.callbacks import EarlyStopping\n","from IPython.display import FileLink, FileLinks\n","import warnings\n","import pprint\n","plt.rc('font', size=16)\n","from sklearn.preprocessing import MinMaxScaler\n","import warnings\n","warnings.filterwarnings('ignore')\n","tf.get_logger().setLevel('ERROR')\n","\n","tfk = tf.keras\n","tfkl = tf.keras.layers\n","print(tf.__version__)\n","\n","from keras.layers.embeddings import Embedding\n","from keras.preprocessing import sequence\n","\n","# fix random seed for reproducibility\n","np.random.seed(42)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["(47252, 10)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Data loading\n","mat = scipy.io.loadmat('/home/nicolo/Scrivania/mat/pydata.mat')\n","data = mat[\"data\"]\n","\n","# Data correction\n","temp = abs(data) > 3\n","data[temp] = data[temp]/1000\n","data.shape"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Data preprocessing\n","psm1 = data[:,[1,2,3]].astype('float64')\n","psm2 = data[:,[4,5,6]].astype('float64')\n","\n","cam = data[:,0].astype('int')\n","psm_features = data[:,[1,2,3,4,5,6]].astype('float64')\n","\n","# psm1x = data[:,1].astype('float64')\n","# psm1y = data[:,2].astype('float64')\n","# psm1z = data[:,3].astype('float64')\n","# psm2x = data[:,4].astype('float64')\n","# psm2y = data[:,5].astype('float64')\n","# psm2z = data[:,6].astype('float64')\n","\n","ecmx = data[:,7].astype('float64')\n","ecmy = data[:,8].astype('float64')\n","ecmz = data[:,9].astype('float64')\n","\n","dist = np.sqrt(np.sum((psm1-psm2)**2, axis=1))"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["4323"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Cam = 2 signal elimination\n","loc = cam==2\n","cam[loc] = 0\n","np.sum(cam)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Camera pedal has been pressed n times:  119\n","Camera pedal has been released n times:  119\n","First press at:  61\n","First release at:  101\n"]}],"source":["# Clutch vector creation\n","difference = cam[1:]-cam[:-1]\n","\n","press = np.where(difference==1)[0][:]\n","release_temp = np.where(difference==-1)[0][:]\n","release = release_temp[1:]\n","\n","clutch_pressed = difference == 1\n","clutch_released = difference == -1\n","\n","clutch = np.zeros(cam.shape[0]-1)\n","clutch[clutch_pressed] = 1\n","clutch = np.insert(clutch, 0, 0, axis=0)\n","\n","print(\"Camera pedal has been pressed n times: \", press.shape[0])\n","print(\"Camera pedal has been released n times: \", release.shape[0])\n","print(\"First press at: \", press[0])\n","print(\"First release at: \", release[0])"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Usable clutches:  112.0\n"]}],"source":["# Selection of usable windows\n","len=30\n","n_variables = 7\n","telescope = 3\n","samples = cam.shape[0]\n","\n","p = press[1:]\n","r = release[:-1]\n","\n","usable = np.where(clutch == 1)[0][:]\n","unusable = np.where((p-r)<len+telescope)[0][:]\n","clutch[press[unusable]+1] = 0\n","print(\"Usable clutches: \", np.sum(clutch))"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Windows matrix dimensions:  (47219, 30, 7)\n","Features matrix dimensions:  (47252, 7)\n","First camera movement at timestamp:  62\n"]}],"source":["# Empty matrices creation\n","distance=np.expand_dims(dist, axis=1)\n","\n","windows = np.zeros((cam.shape[0]-len-telescope,len,n_variables))\n","features = np.concatenate((psm_features,distance), axis=1)\n","print(\"Windows matrix dimensions: \", windows.shape)\n","print(\"Features matrix dimensions: \", features.shape)\n","\n","label_vector = np.zeros((samples-len-telescope,1))\n","label_matrix_temp = np.zeros((samples-len-telescope,n_variables))\n","\n","# If the starting clutch is before len+telescope, we cannot label it\n","index = np.where(clutch==1)\n","print(\"First camera movement at timestamp: \", index[0][0])"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Matrix containing camera windows labels at each timestamp:  (47219, 1)\n","Matrix containing kinematic features at each timestamp:  (47219, 30, 7)\n"]}],"source":["# Useful matrices creation\n","label_vector[usable-len-telescope] = 1;\n","print('Matrix containing camera windows labels at each timestamp: ', label_vector.shape)\n","# label_matrix_temp[usable-len-telescope] = 1;\n","\n","for j in range(n_variables):\n","    for i in range(samples-len-telescope):\n","        temp = features[i:i+len,j]\n","        windows[i,:,j] = temp\n","\n","print(\"Matrix containing kinematic features at each timestamp: \", windows.shape)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X_train shape:  (35414, 30, 7)\n","y_train shape:  (35414, 1)\n","X_test shape:  (11805, 30, 7)\n","y_test shape:  (11805, 1)\n"]}],"source":["# Stratified train-test split\n","from sklearn.model_selection import train_test_split \n","X_train, X_test, y_train, y_test = train_test_split(windows, label_vector, test_size=0.25, stratify=label_vector)\n","\n","print(\"X_train shape: \", X_train.shape)\n","print(\"y_train shape: \", y_train.shape)\n","print(\"X_test shape: \", X_test.shape)\n","print(\"y_test shape: \", y_test.shape)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Input shape:  (30, 7)\n","Output shape:  (1,)\n"]}],"source":["# Shapes\n","input_shape = windows.shape[1:]\n","output_shape = label_vector.shape[1:]\n","print('Input shape: ', input_shape)\n","print('Output shape: ', output_shape)"]},{"cell_type":"code","execution_count":15,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-03-29 11:53:21.113663: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n","2022-03-29 11:53:21.113686: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n","2022-03-29 11:53:21.113705: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (nicolo-Inspiron-14-5410): /proc/driver/nvidia/version does not exist\n","2022-03-29 11:53:21.113968: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"cnn_lstm_model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Input (InputLayer)           [(None, 30, 7)]           0         \n","_________________________________________________________________\n","bidirectional (Bidirectional (None, 30, 128)           36864     \n","_________________________________________________________________\n","conv1d (Conv1D)              (None, 30, 64)            24640     \n","_________________________________________________________________\n","max_pooling1d (MaxPooling1D) (None, 15, 64)            0         \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 15, 128)           66048     \n","_________________________________________________________________\n","conv1d_1 (Conv1D)            (None, 15, 128)           49280     \n","_________________________________________________________________\n","global_average_pooling1d (Gl (None, 128)               0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 128)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 1)                 129       \n","=================================================================\n","Total params: 176,961\n","Trainable params: 176,961\n","Non-trainable params: 0\n","_________________________________________________________________\n","('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"]}],"source":["def build_CONV_LSTM_model(input_shape, output_shape):\n","    # Build the neural network layer by layer\n","    input_layer = tfkl.Input(shape=input_shape, name='Input')\n","\n","    convlstm = tfkl.Bidirectional(tfkl.LSTM(64, return_sequences=True))(input_layer)\n","    convlstm = tfkl.Conv1D(64, 3, padding='same', activation='relu')(convlstm)\n","    convlstm = tfkl.MaxPool1D()(convlstm)\n","    convlstm = tfkl.Bidirectional(tfkl.LSTM(64, return_sequences=True))(convlstm)\n","    convlstm = tfkl.Conv1D(128, 3, padding='same', activation='relu')(convlstm)\n","    convlstm = tfkl.GlobalAveragePooling1D()(convlstm)\n","    convlstm = tfkl.Dropout(.3)(convlstm)\n","\n","    # In order to predict the next values for more than one sensor,\n","    # we can use a Dense layer with a number given by telescope*num_sensors,\n","    # followed by a Reshape layer to obtain a tensor of dimension \n","    # [None, telescope, num_sensors]\n","    output_layer = tfkl.Dense(output_shape[-1]*1, activation='sigmoid')(convlstm)\n","    #output_layer = tfkl.Reshape((1,output_shape[-1]))(output_layer)\n","    #output_layer = tfkl.Conv1D(output_shape[-1], 1, padding='same')(output_layer)\n","\n","    # Connect input and output through the Model class\n","    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='cnn_lstm_model')\n","\n","    # Compile the model\n","    model.compile(loss=tfk.losses.BinaryCrossentropy(), optimizer=tfk.optimizers.Adam(lr = 1e-3),\n","                  metrics=tf.keras.metrics.Accuracy())\n","    # Return the model\n","    return model\n","\n","\n","model = build_CONV_LSTM_model(input_shape, output_shape)\n","model.summary()\n","tfk.utils.plot_model(model, expand_nested=True)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{0.0: 1.0, 1.0: 4.146932776767107}\n"]}],"source":["import numpy as np\n","import math\n","\n","# labels_dict : {ind_label: count_label}\n","# mu : parameter to tune \n","\n","def create_class_weight(labels_dict,mu=0.15):\n","    total = np.sum(list(labels_dict.values()))\n","    keys = labels_dict.keys()\n","    class_weights = dict()\n","    \n","    for key in keys:\n","        score = math.log(mu*total/float(labels_dict[key]))\n","        class_weights[key] = score if score > 1.0 else 1.0\n","    \n","    return class_weights\n","\n","labels_dict = {0.0: 47107,\n","               1.0: 112}\n","\n","class_weights = create_class_weight(labels_dict)\n","pprint.pprint(class_weights)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":["(35414,)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["y_train[:,0].shape"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.50125973 0.50125973 0.50125973 ... 0.50125973 0.50125973 0.50125973]\n","{0: 0.5012597310686483, 1: 198.95505617977528}\n"]}],"source":["# Another option from scikit-learn \n","from sklearn.utils import class_weight\n","import numpy as np\n","\n","cls_weights = class_weight.compute_class_weight('balanced', np.unique(y_train[:,0]), y_train[:,0])\n","cls_weight_dict = {0: cls_weights[0], 1: cls_weights[1]}\n","val_sample_weights = class_weight.compute_sample_weight(cls_weight_dict, y_test)\n","\n","print(val_sample_weights)\n","pprint.pprint(cls_weight_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# class_weights = {0.0: 112/47219,\n","#                  1.0: 47107/47219}\n","# pprint.pprint(class_weights)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-03-29 12:03:38.657160: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","68/68 [==============================] - 17s 183ms/step - loss: 0.6989 - accuracy: 0.0000e+00 - val_loss: 0.6072 - val_accuracy: 0.0000e+00\n","Epoch 2/100\n","68/68 [==============================] - 11s 165ms/step - loss: 0.6971 - accuracy: 0.0000e+00 - val_loss: 0.7705 - val_accuracy: 0.0000e+00\n","Epoch 3/100\n","68/68 [==============================] - 11s 166ms/step - loss: 0.7036 - accuracy: 0.0000e+00 - val_loss: 0.6874 - val_accuracy: 0.0000e+00\n","Epoch 4/100\n","68/68 [==============================] - 11s 165ms/step - loss: 0.6947 - accuracy: 0.0000e+00 - val_loss: 0.6986 - val_accuracy: 0.0000e+00\n","\n","Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n","Epoch 5/100\n","68/68 [==============================] - 11s 165ms/step - loss: 0.6934 - accuracy: 0.0000e+00 - val_loss: 0.6971 - val_accuracy: 0.0000e+00\n","Epoch 6/100\n","68/68 [==============================] - 11s 165ms/step - loss: 0.6929 - accuracy: 0.0000e+00 - val_loss: 0.6977 - val_accuracy: 0.0000e+00\n","Epoch 7/100\n","68/68 [==============================] - 11s 166ms/step - loss: 0.6939 - accuracy: 0.0000e+00 - val_loss: 0.6940 - val_accuracy: 0.0000e+00\n","\n","Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n","Epoch 8/100\n","68/68 [==============================] - 11s 167ms/step - loss: 0.6934 - accuracy: 0.0000e+00 - val_loss: 0.6938 - val_accuracy: 0.0000e+00\n","Epoch 9/100\n","68/68 [==============================] - 11s 168ms/step - loss: 0.6931 - accuracy: 0.0000e+00 - val_loss: 0.6939 - val_accuracy: 0.0000e+00\n","Epoch 10/100\n","68/68 [==============================] - 11s 167ms/step - loss: 0.6932 - accuracy: 0.0000e+00 - val_loss: 0.6937 - val_accuracy: 0.0000e+00\n","\n","Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n","Epoch 11/100\n","68/68 [==============================] - 11s 166ms/step - loss: 0.6940 - accuracy: 0.0000e+00 - val_loss: 0.6937 - val_accuracy: 0.0000e+00\n","Epoch 12/100\n","68/68 [==============================] - 12s 170ms/step - loss: 0.6931 - accuracy: 0.0000e+00 - val_loss: 0.6936 - val_accuracy: 0.0000e+00\n","Epoch 13/100\n","68/68 [==============================] - 12s 169ms/step - loss: 0.6940 - accuracy: 0.0000e+00 - val_loss: 0.6937 - val_accuracy: 0.0000e+00\n","\n","Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n","Epoch 14/100\n","68/68 [==============================] - 11s 168ms/step - loss: 0.6927 - accuracy: 0.0000e+00 - val_loss: 0.6937 - val_accuracy: 0.0000e+00\n","Epoch 15/100\n","68/68 [==============================] - 11s 168ms/step - loss: 0.6926 - accuracy: 0.0000e+00 - val_loss: 0.6936 - val_accuracy: 0.0000e+00\n","Epoch 16/100\n","68/68 [==============================] - 11s 169ms/step - loss: 0.6936 - accuracy: 0.0000e+00 - val_loss: 0.6936 - val_accuracy: 0.0000e+00\n","\n","Epoch 00016: ReduceLROnPlateau reducing learning rate to 1e-07.\n","Epoch 17/100\n","68/68 [==============================] - 11s 168ms/step - loss: 0.6936 - accuracy: 0.0000e+00 - val_loss: 0.6936 - val_accuracy: 0.0000e+00\n","Epoch 18/100\n","68/68 [==============================] - 12s 170ms/step - loss: 0.6940 - accuracy: 0.0000e+00 - val_loss: 0.6936 - val_accuracy: 0.0000e+00\n","Epoch 19/100\n","68/68 [==============================] - 12s 171ms/step - loss: 0.6928 - accuracy: 0.0000e+00 - val_loss: 0.6936 - val_accuracy: 0.0000e+00\n","Epoch 20/100\n","68/68 [==============================] - 11s 169ms/step - loss: 0.6927 - accuracy: 0.0000e+00 - val_loss: 0.6936 - val_accuracy: 0.0000e+00\n","Epoch 21/100\n","68/68 [==============================] - 12s 170ms/step - loss: 0.6935 - accuracy: 0.0000e+00 - val_loss: 0.6936 - val_accuracy: 0.0000e+00\n","Restoring model weights from the end of the best epoch.\n","Epoch 00021: early stopping\n"]}],"source":["batch_size = 526\n","epochs = 100\n","\n","history = model.fit(\n","    X_train,\n","    y_train,\n","    batch_size = batch_size,\n","    epochs = epochs,\n","    validation_data = (X_test,  y_test),\n","    class_weight = class_weights,\n","    callbacks = [\n","        tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='min', patience=20, \n","                                    restore_best_weights=True, verbose = 1),\n","        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=3,\n","                                        factor=0.1, min_lr=1e-7, verbose = 1)\n","    ]\n",").history"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# df2 = df2[[\"correlation_Pwave80_lead1\", \"lag_Pwave80_lead1\",\n","#        \"lag_PRintervall80_lead1\", \"msd_PRintervall80_lead1\",\n","#        \"lag_beat80_lead1\", \"correlation_Pwave20_lead1\", \"lag_QRSwave20_lead1\",\n","#        \"lag_Pwave4_lead1\", \"lag_QRSwave4_lead1\",\n","#        \"correlation_PRintervall4_lead1\", \"lag_PRintervall4_lead1\",\n","#        \"values_under_mean_perc_Pwave_lead1\", \"mean_QRScomplex_lead1\",\n","#        \"median_QRScomplex_lead1\", \"values_over_mean_perc_QRScomplex_lead1\",\n","#        \"max_PRintervall_lead1\", \"min_PRintervall_lead1\",\n","#        \"kurtosis_PRintervall_lead1\",\n","#        \"values_under_mean_perc_PRintervall_lead1\", \"max_beat_lead1\",\n","#        \"min_beat_lead1\", \"values_under_mean_perc_beat_lead1\",\n","#        \"correlation_Pwave80_lead2\", \"lag_Pwave80_lead2\",\n","#        \"lag_PRintervall80_lead2\", \"lag_beat80_lead2\",\n","#        \"correlation_Pwave20_lead2\", \"lag_QRSwave20_lead2\", \"msd_beat20_lead2\",\n","#        \"lag_Pwave4_lead2\", \"lag_QRSwave4_lead2\",\n","#        \"correlation_PRintervall4_lead2\", \"lag_PRintervall4_lead2\",\n","#        \"lag_beat4_lead2\", \"values_under_mean_perc_Pwave_lead2\",\n","#        \"mean_QRScomplex_lead2\", \"median_QRScomplex_lead2\",\n","#        \"der_std_QRScomplex_lead2\", \"max_PRintervall_lead2\",\n","#        \"min_PRintervall_lead2\", \"kurtosis_PRintervall_lead2\",\n","#        \"values_under_mean_perc_PRintervall_lead2\",\n","#        \"max_min_diff_PRintervall_lead2\", \"max_beat_lead2\", \"min_beat_lead2\",\n","#        \"values_under_mean_perc_beat_lead2\", \"mean_rr_30s_back\",\n","#        \"std_drr_30s_back\", \"std_drr_60s_back\", \"mean_rr_120s_current\",\n","#        \"pNN50_120s_current\", \"rmssd_120s_current\",\"beats\",\"frequency\"]]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# df_dict = {}\n","# for i in range(320):\n","#     df_dict[f\"df_predictions_{i}\"] = pd.DataFrame(columns = [\"predictions\",\"predictions_letter\"])\n","    \n","# for i in range(320):\n","#     matrix = df2[\"beats\" == i]\n","#     if matrix[\"frequency\"][1] == 250\n","#         prediction = model1.predict(X1)\n","#     else\n","#         prediction = model2.predict(X2)\n","    \n","#     df_dict[f\"df_predictions_{i}\"][\"predictions\"] = predictions\n","#     df_dict[f\"df_predictions_{i}\"][\"predictions_letter\"] = 'N' if df_dict[f\"df_predictions_{i}\"][\"predictions_letter\"] == 0 else  'S' if f_dict[f\"df_predictions_{i}\"][\"predictions_letter\"] == 1 else 'V'\n","    \n","# #     DF250.to_csv(\"tabella250.csv\", index=False)\n","# #     DF128.to_csv(\"Satisfaction.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# DF250 = pd.DataFrame(prediction250)\n","# DF128 = pd.DataFrame(prediction128)\n","# DF250.to_csv(\"tabella250.csv\", index=False)\n","# DF128.to_csv(\"Satisfaction.csv\", index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
