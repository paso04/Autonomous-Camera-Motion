{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 16:55:45.726521: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow version 2.9.1\n",
      "RNG seed:  420\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras as tfk\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy import array, argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Using TensorFlow version\", tf.__version__)\n",
    "\n",
    "seed = 420\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "print(\"RNG seed: \",seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now reading file:  /home/npasini1/Desktop/dVRK_UserStudy/dVRK_pyrecorder/labeled/AnChi2.csv\n",
      "(9750, 5, 17)\n",
      "(9750, 5, 17)\n",
      "(9750,)\n",
      "(9750,)\n",
      "-#-#-#-#-#-#-#-#-#-#-#-#-\n",
      "(9750, 5, 17)\n",
      "(9750, 5, 17)\n",
      "(9750,)\n",
      "(9750,)\n",
      "Now reading file:  /home/npasini1/Desktop/dVRK_UserStudy/dVRK_pyrecorder/labeled/Mojtaba1.csv\n",
      "(2589, 5, 17)\n",
      "(12339, 5, 17)\n",
      "(2589,)\n",
      "(12339,)\n",
      "-#-#-#-#-#-#-#-#-#-#-#-#-\n",
      "(2589, 5, 17)\n",
      "(12339, 5, 17)\n",
      "(2589,)\n",
      "(12339,)\n",
      "Now reading file:  /home/npasini1/Desktop/dVRK_UserStudy/dVRK_pyrecorder/labeled/Aabhas2.csv\n",
      "(7865, 5, 17)\n",
      "(20204, 5, 17)\n",
      "(7865,)\n",
      "(20204,)\n",
      "-#-#-#-#-#-#-#-#-#-#-#-#-\n",
      "(7865, 5, 17)\n",
      "(20204, 5, 17)\n",
      "(7865,)\n",
      "(20204,)\n",
      "Now reading file:  /home/npasini1/Desktop/dVRK_UserStudy/dVRK_pyrecorder/labeled/Hisashi1.csv\n",
      "(4096, 5, 17)\n",
      "(24300, 5, 17)\n",
      "(4096,)\n",
      "(24300,)\n",
      "-#-#-#-#-#-#-#-#-#-#-#-#-\n",
      "(4096, 5, 17)\n",
      "(24300, 5, 17)\n",
      "(4096,)\n",
      "(24300,)\n",
      "Now reading file:  /home/npasini1/Desktop/dVRK_UserStudy/dVRK_pyrecorder/labeled/AnChi1.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/npasini1/Desktop/scripts/pyrecorder/notebooks/pyrecorder_model_separate.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/npasini1/Desktop/scripts/pyrecorder/notebooks/pyrecorder_model_separate.ipynb#ch0000002?line=61'>62</a>\u001b[0m         df_copy\u001b[39m.\u001b[39miloc[idx\u001b[39m+\u001b[39mj,[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m7\u001b[39m,\u001b[39m8\u001b[39m,\u001b[39m9\u001b[39m]] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[idx\u001b[39m+\u001b[39mj, [\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m7\u001b[39m,\u001b[39m8\u001b[39m,\u001b[39m9\u001b[39m]]\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64) \u001b[39m-\u001b[39m df\u001b[39m.\u001b[39miloc[idx, [\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m7\u001b[39m,\u001b[39m8\u001b[39m,\u001b[39m9\u001b[39m]]\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/npasini1/Desktop/scripts/pyrecorder/notebooks/pyrecorder_model_separate.ipynb#ch0000002?line=62'>63</a>\u001b[0m     sx_dataset \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(sx_dataset, np\u001b[39m.\u001b[39mexpand_dims(df_copy\u001b[39m.\u001b[39miloc[idx:idx\u001b[39m+\u001b[39mtimestep, [\u001b[39m7\u001b[39m,\u001b[39m8\u001b[39m,\u001b[39m9\u001b[39m,\u001b[39m10\u001b[39m,\u001b[39m11\u001b[39m,\u001b[39m12\u001b[39m,\u001b[39m13\u001b[39m,\u001b[39m20\u001b[39m,\u001b[39m21\u001b[39m,\u001b[39m22\u001b[39m,\u001b[39m23\u001b[39m,\u001b[39m24\u001b[39m,\u001b[39m25\u001b[39m,\u001b[39m29\u001b[39m,\u001b[39m30\u001b[39m,\u001b[39m31\u001b[39m,\u001b[39m32\u001b[39m]], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m),axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/npasini1/Desktop/scripts/pyrecorder/notebooks/pyrecorder_model_separate.ipynb#ch0000002?line=63'>64</a>\u001b[0m     dx_dataset \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(dx_dataset, np\u001b[39m.\u001b[39mexpand_dims(df_copy\u001b[39m.\u001b[39;49miloc[idx:idx\u001b[39m+\u001b[39;49mtimestep, [\u001b[39m0\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m3\u001b[39;49m,\u001b[39m4\u001b[39;49m,\u001b[39m5\u001b[39;49m,\u001b[39m6\u001b[39;49m,\u001b[39m14\u001b[39;49m,\u001b[39m15\u001b[39;49m,\u001b[39m16\u001b[39;49m,\u001b[39m17\u001b[39;49m,\u001b[39m18\u001b[39;49m,\u001b[39m19\u001b[39;49m,\u001b[39m26\u001b[39;49m,\u001b[39m27\u001b[39;49m,\u001b[39m28\u001b[39;49m,\u001b[39m32\u001b[39;49m]], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m),axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/npasini1/Desktop/scripts/pyrecorder/notebooks/pyrecorder_model_separate.ipynb#ch0000002?line=64'>65</a>\u001b[0m     j\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/npasini1/Desktop/scripts/pyrecorder/notebooks/pyrecorder_model_separate.ipynb#ch0000002?line=66'>67</a>\u001b[0m sx_dataset_gesture_array \u001b[39m=\u001b[39m sx_gesture_array[timestep\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py:961\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m    960\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m--> 961\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[1;32m    962\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m    964\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py:1462\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1459\u001b[0m \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_lowerdim(tup)\n\u001b[0;32m-> 1462\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py:827\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_null_slice(key):\n\u001b[1;32m    825\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 827\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(retval, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[1;32m    828\u001b[0m \u001b[39m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \u001b[39m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[39massert\u001b[39;00m retval\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py:1497\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1491\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\n\u001b[1;32m   1492\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mDataFrame indexer is not allowed for .iloc\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1493\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConsider using .loc for automatic alignment.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1494\u001b[0m     )\n\u001b[1;32m   1496\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mslice\u001b[39m):\n\u001b[0;32m-> 1497\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_slice_axis(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   1499\u001b[0m \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   1500\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py:1533\u001b[0m, in \u001b[0;36m_iLocIndexer._get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   1531\u001b[0m labels \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1532\u001b[0m labels\u001b[39m.\u001b[39m_validate_positional_slice(slice_obj)\n\u001b[0;32m-> 1533\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_slice(slice_obj, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py:3917\u001b[0m, in \u001b[0;36mNDFrame._slice\u001b[0;34m(self, slobj, axis)\u001b[0m\n\u001b[1;32m   3915\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_block_manager_axis(axis)\n\u001b[1;32m   3916\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mget_slice(slobj, axis\u001b[39m=\u001b[39maxis))\n\u001b[0;32m-> 3917\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39;49m__finalize__(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   3919\u001b[0m \u001b[39m# this could be a view\u001b[39;00m\n\u001b[1;32m   3920\u001b[0m \u001b[39m# but only in a single-dtyped view sliceable case\u001b[39;00m\n\u001b[1;32m   3921\u001b[0m is_copy \u001b[39m=\u001b[39m axis \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m result\u001b[39m.\u001b[39m_is_view\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py:5541\u001b[0m, in \u001b[0;36mNDFrame.__finalize__\u001b[0;34m(self, other, method, **kwargs)\u001b[0m\n\u001b[1;32m   5538\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m other\u001b[39m.\u001b[39mattrs:\n\u001b[1;32m   5539\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattrs[name] \u001b[39m=\u001b[39m other\u001b[39m.\u001b[39mattrs[name]\n\u001b[0;32m-> 5541\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mallows_duplicate_labels \u001b[39m=\u001b[39m other\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mallows_duplicate_labels\n\u001b[1;32m   5542\u001b[0m \u001b[39m# For subclasses using _metadata.\u001b[39;00m\n\u001b[1;32m   5543\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mset\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata) \u001b[39m&\u001b[39m \u001b[39mset\u001b[39m(other\u001b[39m.\u001b[39m_metadata):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/flags.py:86\u001b[0m, in \u001b[0;36mFlags.allows_duplicate_labels\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39m@allows_duplicate_labels\u001b[39m\u001b[39m.\u001b[39msetter\n\u001b[1;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mallows_duplicate_labels\u001b[39m(\u001b[39mself\u001b[39m, value: \u001b[39mbool\u001b[39m):\n\u001b[1;32m     85\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mbool\u001b[39m(value)\n\u001b[0;32m---> 86\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_obj()\n\u001b[1;32m     87\u001b[0m     \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThis flag\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms object has been deleted.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# pathName = '/home/npasini1/Desktop/Recordings/csv/separate'\n",
    "pathName = '/home/npasini1/Desktop/dVRK_UserStudy/dVRK_pyrecorder/labeled'\n",
    "numFiles = []\n",
    "\n",
    "timestep = 5\n",
    "stride = 1\n",
    "n_features = 17\n",
    "sx_n_gestures = 2\n",
    "dx_n_gestures = 3\n",
    "# sx_dataset_tot = np.empty((0,timestep,n_features))\n",
    "# dx_dataset_tot = np.empty((0,timestep,n_features))\n",
    "# sx_dataset_tot = []\n",
    "# dx_dataset_tot = []\n",
    "# sx_dataset_gesture_array_tot = np.empty((0))\n",
    "# dx_dataset_gesture_array_tot = np.empty((0))\n",
    "\n",
    "users = []\n",
    "# users = []\n",
    "# users = []\n",
    "# users = []\n",
    "users_dataset_sx = []\n",
    "users_dataset_dx = []\n",
    "sx_encoded_list =[]\n",
    "dx_encoded_list =[]\n",
    "\n",
    "for i in range(9):\n",
    "    delete = users[i]\n",
    "    sx_dataset_tot = np.empty((0,timestep,n_features))\n",
    "    dx_dataset_tot = np.empty((0,timestep,n_features))\n",
    "    sx_dataset_gesture_array_tot = np.empty((0))\n",
    "    dx_dataset_gesture_array_tot = np.empty((0))\n",
    "\n",
    "    fileNames = os.listdir(pathName)\n",
    "    for fileName in fileNames:\n",
    "        if not fileName.endswith(\".csv\") or delete in fileName:\n",
    "            continue\n",
    "        # if fileName.endswith(\".csv\"):\n",
    "        numFiles.append(fileName)\n",
    "        path = os.path.join(pathName, fileName)\n",
    "        print('Now reading file: ', path)\n",
    "        dataframe = pd.read_csv(path)\n",
    "\n",
    "        #encoding\n",
    "        sx_gesture = dataframe['SX Gesture']\n",
    "        dx_gesture = dataframe['DX Gesture']\n",
    "        sx_gesture_array = array(sx_gesture)    #numpy array\n",
    "        dx_gesture_array = array(dx_gesture)    #numpy array\n",
    "\n",
    "        df = dataframe.drop(['SX Gesture','DX Gesture','Timestamps'], axis=1)\n",
    "        # df = pd.DataFrame(df)\n",
    "        # df.head(5)\n",
    "\n",
    "        samples = df.shape[0]\n",
    "        # n_features = df.shape[1]\n",
    "\n",
    "        sx_dataset = np.empty((0,timestep,n_features))\n",
    "        dx_dataset = np.empty((0,timestep,n_features))\n",
    "        df_copy = df.copy()\n",
    "        # print(type(samples),type(timestep))\n",
    "        for idx in range(samples-timestep+1):\n",
    "            for j in range(timestep):\n",
    "                df_copy.iloc[idx+j,[0,1,2,7,8,9]] = df.iloc[idx+j, [0,1,2,7,8,9]].astype(np.float64) - df.iloc[idx, [0,1,2,7,8,9]].astype(np.float64)\n",
    "            sx_dataset = np.append(sx_dataset, np.expand_dims(df_copy.iloc[idx:idx+timestep, [7,8,9,10,11,12,13,20,21,22,23,24,25,29,30,31,32]], axis=0),axis=0)\n",
    "            dx_dataset = np.append(dx_dataset, np.expand_dims(df_copy.iloc[idx:idx+timestep, [0,1,2,3,4,5,6,14,15,16,17,18,19,26,27,28,32]], axis=0),axis=0)\n",
    "            j=0\n",
    "        \n",
    "        sx_dataset_gesture_array = sx_gesture_array[timestep-1:]\n",
    "        dx_dataset_gesture_array = dx_gesture_array[timestep-1:]\n",
    "        sx_dataset_tot = np.append(sx_dataset_tot,sx_dataset, axis=0)\n",
    "        dx_dataset_tot = np.append(dx_dataset_tot,dx_dataset, axis=0)\n",
    "        # sx_dataset_tot.append(sx_dataset)\n",
    "        # dx_dataset_tot.append(dx_dataset)\n",
    "        sx_dataset_gesture_array_tot = np.append(sx_dataset_gesture_array_tot, sx_dataset_gesture_array, axis=0)\n",
    "        dx_dataset_gesture_array_tot = np.append(dx_dataset_gesture_array_tot, dx_dataset_gesture_array, axis=0)\n",
    "        print(sx_dataset.shape)\n",
    "        print(sx_dataset_tot.shape)\n",
    "        # print(len(sx_dataset_tot))\n",
    "        print(sx_dataset_gesture_array.shape)\n",
    "        print(sx_dataset_gesture_array_tot.shape)\n",
    "        print(\"-#-#-#-#-#-#-#-#-#-#-#-#-\")\n",
    "        print(dx_dataset.shape)\n",
    "        print(dx_dataset_tot.shape)\n",
    "        # print(len(dx_dataset_tot))\n",
    "        print(dx_dataset_gesture_array.shape)\n",
    "        print(dx_dataset_gesture_array_tot.shape)\n",
    "\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    sx_integer_encoded = label_encoder.fit_transform(sx_dataset_gesture_array_tot)\n",
    "    dx_integer_encoded = label_encoder.fit_transform(dx_dataset_gesture_array_tot)\n",
    "    print(sx_integer_encoded)\n",
    "    print(dx_integer_encoded)\n",
    "\n",
    "    sx_encoded = to_categorical(sx_integer_encoded)\n",
    "    dx_encoded = to_categorical(dx_integer_encoded)\n",
    "    print(sx_encoded)\n",
    "    print(dx_encoded)\n",
    "\n",
    "    users_dataset_sx.append(sx_dataset_tot)\n",
    "    users_dataset_dx.append(dx_dataset_tot)\n",
    "    sx_encoded_list.append(sx_encoded)\n",
    "    dx_encoded_list.append(dx_encoded)\n",
    "    np.save(\"/home/npasini1/Desktop/dVRK_UserStudy/Datasets/dataset_\" + delete + \"_dx_5.npy\", dx_dataset_tot)\n",
    "    np.save(\"/home/npasini1/Desktop/dVRK_UserStudy/Datasets/labels_\" + delete + \"_dx_5.npy\", dx_encoded)\n",
    "    np.save(\"/home/npasini1/Desktop/dVRK_UserStudy/Datasets/dataset_\" + delete + \"_sx_5.npy\", sx_dataset_tot)\n",
    "    np.save(\"/home/npasini1/Desktop/dVRK_UserStudy/Datasets/labels_\" + delete + \"_sx_5.npy\", sx_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(dx_dataset_gesture_array_tot)):\n",
    "#     if dx_dataset_gesture_array_tot[i] != 'NH' and dx_dataset_gesture_array_tot[i] != 'TB' and dx_dataset_gesture_array_tot[i] != 'NP':\n",
    "#         print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE NAME EVERY TIME\n",
    "\n",
    "# np.save(\"/home/npasini1/Desktop/dVRK_UserStudy/Datasets/dataset_UserStudy_dx_5.npy\", dx_dataset_tot)\n",
    "# np.save(\"/home/npasini1/Desktop/dVRK_UserStudy/Datasets/labels_UserStudy_dx_5.npy\", dx_encoded)\n",
    "# np.save(\"/home/npasini1/Desktop/dVRK_UserStudy/Datasets/dataset_UserStudy_sx_5.npy\", sx_dataset_tot)\n",
    "# np.save(\"/home/npasini1/Desktop/dVRK_UserStudy/Datasets/labels_UserStudy_sx_5.npy\", sx_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE NAME EVERY TIME\n",
    "\n",
    "# sx_dataset_tot = np.load(\"/home/npasini1/Desktop/dVRK_UserStudy/Datasets/dataset_UserStudy_sx_5.npy\")\n",
    "# sx_encoded = np.load(\"/home/npasini1/Desktop/dVRK_UserStudy/Datasets/labels_UserStudy_sx_5.npy\")\n",
    "# dx_dataset_tot = np.load(\"/home/npasini1/Desktop/dVRK_UserStudy/Datasets/dataset_UserStudy_dx_5.npy\")\n",
    "# dx_encoded = np.load(\"/home/npasini1/Desktop/dVRK_UserStudy/Datasets/labels_UserStudy_dx_5.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 5\n",
    "stride = 1\n",
    "n_features = 17\n",
    "sx_n_gestures = 2\n",
    "dx_n_gestures = 3\n",
    "input_shape = (5,17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sx_X_train, sx_X_test, sx_y_train, sx_y_test = train_test_split(sx_dataset_tot, sx_encoded, test_size=0.10, shuffle = True)\n",
    "# dx_X_train, dx_X_test, dx_y_train, dx_y_test = train_test_split(dx_dataset_tot, dx_encoded, test_size=0.10, shuffle = True)\n",
    "# print(\"Train shape: \", sx_X_train.shape)\n",
    "# print(\"Test shape: \", sx_X_test.shape)\n",
    "\n",
    "# input_shape = sx_X_train.shape[1:]\n",
    "# sx_output_shape = sx_y_train.shape[1:]\n",
    "# dx_output_shape = dx_y_train.shape[1:]\n",
    "# print(\"Input shape: \", input_shape)\n",
    "# print(\"SX Output shape: \", sx_output_shape)\n",
    "# print(\"DX Output shape: \", dx_output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe = pd.read_csv('/home/npasini1/Desktop/Recordings/nic_suture_10.csv')\n",
    "# dataframe = pd.read_csv('/home/npasini1/Desktop/Recordings/new/Nicolo_1.csv')\n",
    "# dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding of Gestures\n",
    "\n",
    "# gesture = dataframe['Predicted Gesture']\n",
    "# values = array(gesture)\n",
    "# print(values)\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# integer_encoded = label_encoder.fit_transform(values)\n",
    "# print(integer_encoded)\n",
    "\n",
    "# encoded = to_categorical(integer_encoded)\n",
    "# print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(integer_encoded[793])\n",
    "# print(values[793])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization\n",
    "\n",
    "# labels = encoded\n",
    "# df = dataframe.drop(['Predicted Gesture','Timestamps'], axis=1)\n",
    "\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# df_scaled = min_max_scaler.fit_transform(df)\n",
    "# df_scaled = pd.DataFrame(df_scaled)\n",
    "# df_scaled.head\n",
    "\n",
    "# df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = df.shape[0]\n",
    "# n_features = df.shape[1]\n",
    "# timestep = 30\n",
    "# stride = 1\n",
    "\n",
    "# dataset = np.empty((0,timestep,n_features))\n",
    "# df_copy = df\n",
    "# np_scaled = np.array(df_scaled)\n",
    "# print(dataset.shape)\n",
    "\n",
    "# CON PREPROCESSING DEI DATI: MINMAX SCALER\n",
    "\n",
    "# for idx in range(samples-timestep):\n",
    "#     dataset = np.append(dataset, np.expand_dims(df_scaled[idx:idx+timestep], axis=0),axis=0)\n",
    "#     # print(idx)\n",
    "\n",
    "# SENZA PREPROCESSING DEI DATI\n",
    "\n",
    "\n",
    "# for idx in range(samples-timestep):\n",
    "#     for j in range(timestep):\n",
    "#         df_copy.iloc[idx+j,[0,1,2,7,8,9]] = df.iloc[idx+j, [0,1,2,7,8,9]] - df.iloc[idx, [0,1,2,7,8,9]]\n",
    "#     dataset = np.append(dataset, np.expand_dims(df_copy[idx:idx+timestep], axis=0),axis=0)\n",
    "#     j=0\n",
    "\n",
    "# print(dataset.shape)\n",
    "# dataset_labels = labels[timestep:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_labels = labels[timestep:]\n",
    "# print(dataset_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(dataset, dataset_labels, test_size=0.10, shuffle = True)\n",
    "# print(\"Train shape: \", X_train.shape)\n",
    "# print(\"Test shape: \", X_test.shape)\n",
    "\n",
    "# input_shape = X_train.shape[1:]\n",
    "# output_shape = y_train.shape[1:]\n",
    "# print(\"Input shape: \", input_shape)\n",
    "# print(\"Output shape: \", output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras as tfk\n",
    "import keras.layers as tfkl\n",
    "import scipy.io\n",
    "import os, glob, sys, pickle, time, math, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, load_model\n",
    "from keras import optimizers\n",
    "from keras.utils import plot_model\n",
    "from keras import layers #Dense, LSTM, RepeatVector, TimeDistributed, Dropout, Masking, BatchNormalization, Flatten, Input, Conv2D, MaxPooling1D, Conv1D, Reshape, GRU\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, CSVLogger\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import backend as K\n",
    "from datetime import datetime\n",
    "\n",
    "def buildModelv2(timestep, n_gestures):\n",
    "    \"\"\"\n",
    "    An lstm-encoder model followed by dense layers, similar performance to just lstm\n",
    "    \"\"\"\n",
    "    # lstm_hidden1 = 128 #*4\n",
    "    # lstm_hidden2 = 64\n",
    "    # dense_hidden1 = 64\n",
    "    # output_layer = 15\n",
    "\n",
    "    model_input = layers.Input(shape=input_shape)\n",
    "    lstm_output = layers.LSTM(128, input_shape=input_shape, kernel_regularizer=tfk.regularizers.l1(l=0.001), return_sequences=True)(model_input) #previously 96\n",
    "    dropout_output = layers.Dropout(rate=0.2)(lstm_output) #previously 0.4\n",
    "    batch_norm1 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True)(dropout_output)\n",
    "    lstm_output2 = layers.LSTM(64, input_shape=input_shape, kernel_regularizer=tfk.regularizers.l1(l=0.001), return_sequences=False)(batch_norm1)\n",
    "    dropout_output = layers.Dropout(rate = 0.3)(lstm_output2)\n",
    "    batch_norm2 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True)(dropout_output)\n",
    "    repeat_vector = layers.RepeatVector(timestep)(batch_norm2)\n",
    "\n",
    "    flatten_output = layers.Flatten()(repeat_vector)\n",
    "    batch_norm2 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True)(flatten_output)\n",
    "    dropout_output = layers.Dropout(rate = 0.2)(batch_norm2)\n",
    "    dense_output1 = layers.Dense(64, activation='relu')(dropout_output)\n",
    "    batch_norm3 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True)(dense_output1)\n",
    "    dense_output2 = layers.Dense(n_gestures, activation='softmax')(batch_norm3)\n",
    "    lstm_classifier = Model(inputs=model_input, outputs=dense_output2)\n",
    "    \n",
    "    #Compile the model\n",
    "    lstm_classifier.compile(loss=tfk.losses.categorical_crossentropy, optimizer=tfk.optimizers.Adam(1e-3), metrics=[tfk.metrics.categorical_accuracy])\n",
    "\n",
    "    return lstm_classifier\n",
    "\n",
    "# def buildModelv1(timesteps, n_features):\n",
    "#     \"\"\"\n",
    "#     Simple model which yields a high accuracy of 90% on training data but sucks on the validation data\n",
    "#     \"\"\"\n",
    "#     model_input = layers.Input(shape=input_shape)\n",
    "#     lstm_output = layers.LSTM(128, input_shape=input_shape, kernel_regularizer=tfk.regularizers.l1(l=0.001), return_sequences=True)(model_input)\n",
    "#     dropout_output = layers.Dropout(rate=0.2)(lstm_output)\n",
    "#     flatten_output = layers.Flatten()(dropout_output)\n",
    "#     dense_output1 = layers.Dense(64, activation='relu')(flatten_output)\n",
    "#     dropout_output2 = layers.Dropout(rate=0.2)(dense_output1)\n",
    "#     dense_output2 = layers.Dense(4, activation='softmax')(dropout_output2)\n",
    "#     lstm_classifier = Model(model_input, dense_output2)\n",
    "#     #lstm_classifier.summary()\n",
    "#     lstm_classifier.compile(loss=tfk.losses.categorical_crossentropy, optimizer=tfk.optimizers.Adam(1e-3))\n",
    "\n",
    "#     return lstm_classifier\n",
    "\n",
    "sx_model = buildModelv2(timestep, sx_n_gestures)\n",
    "dx_model = buildModelv2(timestep, dx_n_gestures)\n",
    "dx_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE NAME EVERY TIME\n",
    "\n",
    "# sx_mc = tfk.callbacks.ModelCheckpoint('/home/npasini1/Desktop/dVRK_UserStudy/model_checkpoints/UserStudy_sx_5_ALL.h5',\n",
    "#                                         monitor='loss',\n",
    "#                                         mode = 'min',\n",
    "#                                         save_best_only=True,\n",
    "#                                         verbose=1)\n",
    "\n",
    "# dx_mc = tfk.callbacks.ModelCheckpoint('/home/npasini1/Desktop/dVRK_UserStudy/model_checkpoints/UserStudy_dx_5_ALL.h5',\n",
    "#                                         monitor='loss',\n",
    "#                                         mode = 'min',\n",
    "#                                         save_best_only=True,\n",
    "#                                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "for i in range(9):\n",
    "    sx_model = buildModelv2(timestep, sx_n_gestures)\n",
    "    tfk.backend.clear_session()\n",
    "    user = users[i]\n",
    "    sx_mc = tfk.callbacks.ModelCheckpoint('/home/npasini1/Desktop/dVRK_UserStudy/model_checkpoints/batch256/' + user + '_sx_5_256.h5',\n",
    "                                        monitor='loss',\n",
    "                                        mode = 'min',\n",
    "                                        save_best_only=True,\n",
    "                                        verbose=1)\n",
    "    sx_data = users_dataset_sx[i]\n",
    "    sx_labels = sx_encoded_list[i]\n",
    "    history = sx_model.fit(\n",
    "        # x = sx_datadataset_tot,\n",
    "        x = sx_data,\n",
    "        # y = sx_encoded,\n",
    "        y = sx_labels,\n",
    "        batch_size = batch_size,\n",
    "        epochs = 2000,\n",
    "        # validation_split=.20,\n",
    "        #validation_steps=10,\n",
    "        shuffle=False,\n",
    "        callbacks = [\n",
    "            tfk.callbacks.EarlyStopping(monitor='loss', mode='min', patience=210),\n",
    "            tfk.callbacks.ReduceLROnPlateau(monitor='loss', mode='min', patience=40, factor=0.5, min_lr=1e-5),\n",
    "            sx_mc\n",
    "        ]\n",
    "    ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "for i in range(9):\n",
    "    dx_model = buildModelv2(timestep, dx_n_gestures)\n",
    "    tfk.backend.clear_session()\n",
    "    user = users[i]\n",
    "    dx_mc = tfk.callbacks.ModelCheckpoint('/home/npasini1/Desktop/dVRK_UserStudy/model_checkpoints/batch256/' + user + '_dx_5_256.h5',\n",
    "                                        monitor='loss',\n",
    "                                        mode = 'min',\n",
    "                                        save_best_only=True,\n",
    "                                        verbose=1)\n",
    "    dx_data = users_dataset_dx[i]\n",
    "    dx_labels = dx_encoded_list[i]\n",
    "    history = dx_model.fit(\n",
    "        # x = dx_dataset_tot,\n",
    "        x = dx_data,\n",
    "        # y = dx_encoded,\n",
    "        y = dx_labels,\n",
    "        batch_size = batch_size,\n",
    "        epochs = 2000,\n",
    "        # validation_split=.20,\n",
    "        #validation_steps=10,\n",
    "        shuffle=False,\n",
    "        callbacks = [\n",
    "            tfk.callbacks.EarlyStopping(monitor='loss', mode='min', patience=210),\n",
    "            tfk.callbacks.ReduceLROnPlateau(monitor='loss', mode='min', patience=40, factor=0.5, min_lr=1e-5),\n",
    "            dx_mc\n",
    "        ]\n",
    "    ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sx_model.save('/home/npasini1/Desktop/dVRK_UserStudy/model_save/UserStudy_sx_5_modelsave_ALL.h5')\n",
    "# dx_model.save('/home/npasini1/Desktop/dVRK_UserStudy/model_save/UserStudy_dx_5_modelsave_ALL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sx_model.evaluate(sx_X_test, sx_y_test)\n",
    "# dx_model.evaluate(dx_X_test, dx_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(np.expand_dims(X_test[0],0))\n",
    "# def a():\n",
    "#     prediction = model.predict(np.expand_dims(X_RealTime,axis=0), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(np.expand_dims(X_test[34],0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tfk.models.load_model('/home/npasini1/nicolo_ws/src/pyrecorder/src/bestmodel_v2_senzapreprocessing.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tfk.models.load_model('/home/npasini1/Desktop/model_checkpoints/magnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = model.predict(X_test)\n",
    "# print(X_test.shape)\n",
    "# prediction = np.argmax(a, axis=1)\n",
    "# print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
