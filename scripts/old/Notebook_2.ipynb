{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# %pip install tensorflow==2.6.2"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Importing libraries\n","\n","import tensorflow as tf\n","import tensorflow.keras as tfk\n","import tensorflow.keras.layers as tfkl\n","import numpy as np\n","import scipy.io\n","import os\n","import random\n","import pandas as pd\n","import seaborn as sns\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","import keras.backend as K\n","import numpy as np\n","import os\n","import random\n","import seaborn as sns\n","from datetime import datetime\n","from random import randrange\n","import matplotlib.pyplot as plt\n","import math\n","plt.rc('font', size=16)\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.layers import Lambda\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense, Bidirectional, Concatenate\n","from tensorflow.keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Input, BatchNormalization, \\\n","    multiply, concatenate, Flatten, Activation, dot\n","from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import Sequence\n","from tensorflow.keras.callbacks import EarlyStopping\n","from IPython.display import FileLink, FileLinks\n","import warnings\n","import pprint\n","plt.rc('font', size=16)\n","from sklearn.preprocessing import MinMaxScaler\n","import warnings\n","warnings.filterwarnings('ignore')\n","tf.get_logger().setLevel('ERROR')\n","\n","tfk = tf.keras\n","tfkl = tf.keras.layers\n","print(tf.__version__)\n","\n","from keras.layers.embeddings import Embedding\n","from keras.preprocessing import sequence\n","\n","# fix random seed for reproducibility\n","np.random.seed(42)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Data loading\n","mat = scipy.io.loadmat('/home/nicolo/Scrivania/mat/pydata.mat')\n","data = mat[\"data\"]\n","\n","# Data correction\n","temp = abs(data) > 3\n","data[temp] = data[temp]/1000\n","data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Data preprocessing\n","psm1 = data[:,[1,2,3]].astype('float64')\n","psm2 = data[:,[4,5,6]].astype('float64')\n","\n","cam = data[:,0].astype('int')\n","psm_features = data[:,[1,2,3,4,5,6]].astype('float64')\n","\n","# psm1x = data[:,1].astype('float64')\n","# psm1y = data[:,2].astype('float64')\n","# psm1z = data[:,3].astype('float64')\n","# psm2x = data[:,4].astype('float64')\n","# psm2y = data[:,5].astype('float64')\n","# psm2z = data[:,6].astype('float64')\n","\n","ecmx = data[:,7].astype('float64')\n","ecmy = data[:,8].astype('float64')\n","ecmz = data[:,9].astype('float64')\n","\n","dist = np.sqrt(np.sum((psm1-psm2)**2, axis=1))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Cam = 2 signal elimination\n","loc = cam==2\n","cam[loc] = 0\n","np.sum(cam)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Clutch vector creation\n","difference = cam[1:]-cam[:-1]\n","\n","press = np.where(difference==1)[0][:]\n","release_temp = np.where(difference==-1)[0][:]\n","release = release_temp[1:]\n","\n","clutch_pressed = difference == 1\n","clutch_released = difference == -1\n","\n","clutch = np.zeros(cam.shape[0]-1)\n","clutch[clutch_pressed] = 1\n","clutch = np.insert(clutch, 0, 0, axis=0)\n","\n","print(\"Camera pedal has been pressed n times: \", press.shape[0])\n","print(\"Camera pedal has been released n times: \", release.shape[0])\n","print(\"First press at: \", press[0])\n","print(\"First release at: \", release[0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Selection of usable windows\n","len=30\n","n_variables = 7\n","telescope = 3\n","samples = cam.shape[0]\n","\n","p = press[1:]\n","r = release[:-1]\n","\n","usable = np.where(clutch == 1)[0][:]\n","unusable = np.where((p-r)<len+telescope)[0][:]\n","clutch[press[unusable]+1] = 0\n","print(\"Usable clutches: \", np.sum(clutch))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Empty matrices creation\n","distance=np.expand_dims(dist, axis=1)\n","\n","windows = np.zeros((cam.shape[0]-len-telescope,len,n_variables))\n","features = np.concatenate((psm_features,distance), axis=1)\n","print(\"Windows matrix dimensions: \", windows.shape)\n","print(\"Features matrix dimensions: \", features.shape)\n","\n","label_vector = np.zeros((samples-len-telescope,1))\n","label_matrix_temp = np.zeros((samples-len-telescope,n_variables))\n","\n","# If the starting clutch is before len+telescope, we cannot label it\n","index = np.where(clutch==1)\n","print(\"First camera movement at timestamp: \", index[0][0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Useful matrices creation\n","label_vector[usable-len-telescope] = 1;\n","print('Matrix containing camera windows labels at each timestamp: ', label_vector.shape)\n","# label_matrix_temp[usable-len-telescope] = 1;\n","\n","for j in range(n_variables):\n","    for i in range(samples-len-telescope):\n","        temp = features[i:i+len,j]\n","        windows[i,:,j] = temp\n","\n","print(\"Matrix containing kinematic features at each timestamp: \", windows.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Stratified train-test split\n","from sklearn.model_selection import train_test_split \n","X_train, X_test, y_train, y_test = train_test_split(windows, label_vector, test_size=0.20, stratify=label_vector)\n","\n","print(\"X_train shape: \", X_train.shape)\n","print(\"y_train shape: \", y_train.shape)\n","print(\"X_test shape: \", X_test.shape)\n","print(\"y_test shape: \", y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Shapes\n","input_shape = X_train.shape[1:]\n","output_shape = y_train.shape[1:]\n","print('Input shape: ', input_shape)\n","print('Output shape: ', output_shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import math\n","\n","# labels_dict : {ind_label: count_label}\n","# mu : parameter to tune \n","\n","def create_class_weight(labels_dict,mu=0.15):\n","    total = np.sum(list(labels_dict.values()))\n","    keys = labels_dict.keys()\n","    class_weights = dict()\n","    \n","    for key in keys:\n","        score = math.log(mu*total/float(labels_dict[key]))\n","        class_weights[key] = score if score > 1.0 else 1.0\n","    \n","    return class_weights\n","\n","labels_dict = {0.0: 47107,\n","               1.0: 112}\n","\n","class_weights = create_class_weight(labels_dict)\n","pprint.pprint(class_weights)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n","    # Attention and Normalization\n","    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n","    x = layers.Dropout(dropout)(x)\n","    x = layers.LayerNormalization(epsilon=1e-6)(x)\n","    res = x + inputs\n","\n","    # Feed Forward part\n","    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n","    x = layers.Dropout(dropout)(x)\n","    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n","    x = layers.LayerNormalization(epsilon=1e-6)(x)\n","    return x + res"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def build_model(\n","    input_shape,\n","    head_size,\n","    num_heads,\n","    ff_dim,\n","    num_transformer_blocks,\n","    mlp_units,\n","    dropout=0,\n","    mlp_dropout=0\n","    ):\n","    inputs = tfk.Input(shape=input_shape)\n","    x = inputs\n","    for _ in range(num_transformer_blocks):\n","        x = transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout)\n","\n","    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n","    for dim in range(mlp_units):\n","        x = layers.Dense(dim, activation=\"relu\")(x)\n","        x = layers.Dropout(mlp_dropout)(x)\n","    \n","    outputs = layers.Dense(2, activation=\"softmax\")(x)\n","    return tfk.Model(inputs,outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = build_model(\n","    input_shape,\n","    head_size=256,\n","    num_heads=4,\n","    ff_dim=4,\n","    num_transformer_blocks=4,\n","    mlp_units=128,\n","    mlp_dropout=0.4,\n","    dropout=0.25\n","    )\n","\n","model.compile(\n","    loss=\"sparse_categorical_crossentropy\",\n","    optimizer=tfk.optimizers.Adam(lr = 1e-4),\n","    metrics=[\"sparse_categorical_accuracy\"]\n",")\n","\n","model.summary()\n","\n","callbacks = [tfk.callbacks.EarlyStopping(patience=15, restore_best_weights=True),\n","             tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5,\n","                                        factor=0.1, min_lr=1e-7, verbose = 1)\n","]\n","\n","history = model.fit(\n","    X_train,\n","    y_train,\n","    batch_size = 256,\n","    epochs = 200,\n","    validation_split=0.2,\n","    class_weight = class_weights,\n","    callbacks = callbacks\n",").history\n","\n","model.evaluate(X_test, y_test, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# df2 = df2[[\"correlation_Pwave80_lead1\", \"lag_Pwave80_lead1\",\n","#        \"lag_PRintervall80_lead1\", \"msd_PRintervall80_lead1\",\n","#        \"lag_beat80_lead1\", \"correlation_Pwave20_lead1\", \"lag_QRSwave20_lead1\",\n","#        \"lag_Pwave4_lead1\", \"lag_QRSwave4_lead1\",\n","#        \"correlation_PRintervall4_lead1\", \"lag_PRintervall4_lead1\",\n","#        \"values_under_mean_perc_Pwave_lead1\", \"mean_QRScomplex_lead1\",\n","#        \"median_QRScomplex_lead1\", \"values_over_mean_perc_QRScomplex_lead1\",\n","#        \"max_PRintervall_lead1\", \"min_PRintervall_lead1\",\n","#        \"kurtosis_PRintervall_lead1\",\n","#        \"values_under_mean_perc_PRintervall_lead1\", \"max_beat_lead1\",\n","#        \"min_beat_lead1\", \"values_under_mean_perc_beat_lead1\",\n","#        \"correlation_Pwave80_lead2\", \"lag_Pwave80_lead2\",\n","#        \"lag_PRintervall80_lead2\", \"lag_beat80_lead2\",\n","#        \"correlation_Pwave20_lead2\", \"lag_QRSwave20_lead2\", \"msd_beat20_lead2\",\n","#        \"lag_Pwave4_lead2\", \"lag_QRSwave4_lead2\",\n","#        \"correlation_PRintervall4_lead2\", \"lag_PRintervall4_lead2\",\n","#        \"lag_beat4_lead2\", \"values_under_mean_perc_Pwave_lead2\",\n","#        \"mean_QRScomplex_lead2\", \"median_QRScomplex_lead2\",\n","#        \"der_std_QRScomplex_lead2\", \"max_PRintervall_lead2\",\n","#        \"min_PRintervall_lead2\", \"kurtosis_PRintervall_lead2\",\n","#        \"values_under_mean_perc_PRintervall_lead2\",\n","#        \"max_min_diff_PRintervall_lead2\", \"max_beat_lead2\", \"min_beat_lead2\",\n","#        \"values_under_mean_perc_beat_lead2\", \"mean_rr_30s_back\",\n","#        \"std_drr_30s_back\", \"std_drr_60s_back\", \"mean_rr_120s_current\",\n","#        \"pNN50_120s_current\", \"rmssd_120s_current\",\"beats\",\"frequency\"]]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# df_dict = {}\n","# for i in range(320):\n","#     df_dict[f\"df_predictions_{i}\"] = pd.DataFrame(columns = [\"predictions\",\"predictions_letter\"])\n","    \n","# for i in range(320):\n","#     matrix = df2[\"beats\" == i]\n","#     if matrix[\"frequency\"][1] == 250\n","#         prediction = model1.predict(X1)\n","#     else\n","#         prediction = model2.predict(X2)\n","    \n","#     df_dict[f\"df_predictions_{i}\"][\"predictions\"] = predictions\n","#     df_dict[f\"df_predictions_{i}\"][\"predictions_letter\"] = 'N' if df_dict[f\"df_predictions_{i}\"][\"predictions_letter\"] == 0 else  'S' if f_dict[f\"df_predictions_{i}\"][\"predictions_letter\"] == 1 else 'V'\n","    \n","# #     DF250.to_csv(\"tabella250.csv\", index=False)\n","# #     DF128.to_csv(\"Satisfaction.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# DF250 = pd.DataFrame(prediction250)\n","# DF128 = pd.DataFrame(prediction128)\n","# DF250.to_csv(\"tabella250.csv\", index=False)\n","# DF128.to_csv(\"Satisfaction.csv\", index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
